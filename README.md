# Курсовая

Численное решение задачи граничного управления колебаниями балки
Постановка задачи
Рассматривается уравнение продольных колебаний балки (уравнение Эйлера–Бернулли) с граничным управлением на концах длины $l$:
𝑦
𝑡
𝑡
(
𝑡
,
𝑥
)
+
𝑦
𝑥
𝑥
𝑥
𝑥
(
𝑡
,
𝑥
)
=
0
,
𝑡
∈
(
0
,
𝑇
)
,
  
𝑥
∈
(
0
,
𝑙
)
,
y 
tt
​
 (t,x)+y 
xxxx
​
 (t,x)=0,t∈(0,T),x∈(0,l),
где $y(t,x)$ – поперечное отклонение балки. Управление осуществляется через граничные условия на концах $x=0$ и $x=l$:
𝑦
(
𝑡
,
0
)
=
𝑢
1
(
𝑡
)
,
𝑦
𝑥
𝑥
(
𝑡
,
0
)
=
𝑢
2
(
𝑡
)
,
y(t,0)=u 
1
​
 (t),y 
xx
​
 (t,0)=u 
2
​
 (t),
𝑦
(
𝑡
,
𝑙
)
=
𝑢
3
(
𝑡
)
,
𝑦
𝑥
𝑥
(
𝑡
,
𝑙
)
=
𝑢
4
(
𝑡
)
,
y(t,l)=u 
3
​
 (t),y 
xx
​
 (t,l)=u 
4
​
 (t),
где $u_1(t), u_2(t), u_3(t), u_4(t)$ – заданные управляемые функции времени (смещения и изгибающие моменты на концах). Начальные условия соответствуют покою балки:
𝑦
(
0
,
𝑥
)
=
0
,
𝑦
𝑡
(
0
,
𝑥
)
=
0
,
0
<
𝑥
<
𝑙
.
y(0,x)=0,y 
t
​
 (0,x)=0,0<x<l.
Цель управления – найти такие граничные управления $u_i(t)$, чтобы к конечному моменту $t=T$ балка приняла требуемую форму $f(x)$ (целевое состояние):
𝑦
(
𝑇
,
𝑥
)
=
𝑓
(
𝑥
)
,
0
≤
𝑥
≤
𝑙
,
y(T,x)=f(x),0≤x≤l,
(здесь предполагается, что желаемая конечная скорость $y_t(T,x)$ равна нулю, либо несущественна для цели задачи). Задача: Построить численный алгоритм, позволяющий на шаге по времени корректировать граничные управления $u_1(t), \dots, u_4(t)$ таким образом, чтобы достичь требуемого отклонения $y(T,x) = f(x)$. Решение должно быть получено без явного разложения по собственным формам и без составления и инвертирования глобальной матрицы управляемости; вместо этого используется пошаговый контроль в ходе прямого численного интегрирования уравнения во времени.
Разностная дискретизация по пространству
Для приближенного решения используем конечно-разностную схему по пространству. Разобьем длину балки на $N$ равных участков с шагом $\Delta x = l/N$. Обозначим узлы сетки $x_j = j,\Delta x$ для $j=0,1,\dots,N$, причем $x_0=0$, $x_N=l$. Искомое решение в дискретных узлах будем обозначать $y(t,x_j) = y_j(t)$. В уравнении $y_{xxxx}$ – четвертая производная по координате. Для ее аппроксимации используем центральные разности. Стандартная вторая разность дает приближение для второй производной:
𝑦
𝑥
𝑥
(
𝑡
,
𝑥
𝑗
)
≈
𝑦
𝑗
−
1
(
𝑡
)
−
2
 
𝑦
𝑗
(
𝑡
)
+
𝑦
𝑗
+
1
(
𝑡
)
Δ
𝑥
2
.
y 
xx
​
 (t,x 
j
​
 )≈ 
Δx 
2
 
y 
j−1
​
 (t)−2y 
j
​
 (t)+y 
j+1
​
 (t)
​
 .
Для четвертой производной можно применить эту формулу дважды либо вывести напрямую пятиточечную формулу. Центральная разностная аппроксимация $O(\Delta x^2)$ для четвертой производной имеет вид:
𝑦
𝑥
𝑥
𝑥
𝑥
(
𝑡
,
𝑥
𝑗
)
≈
𝑦
𝑗
−
2
(
𝑡
)
−
4
 
𝑦
𝑗
−
1
(
𝑡
)
+
6
 
𝑦
𝑗
(
𝑡
)
−
4
 
𝑦
𝑗
+
1
(
𝑡
)
+
𝑦
𝑗
+
2
(
𝑡
)
Δ
𝑥
4
,
y 
xxxx
​
 (t,x 
j
​
 )≈ 
Δx 
4
 
y 
j−2
​
 (t)−4y 
j−1
​
 (t)+6y 
j
​
 (t)−4y 
j+1
​
 (t)+y 
j+2
​
 (t)
​
 ,
для узлов, удаленных от границы не менее чем на 2 шага ($j=2,3,\dots,N-2$). Вблизи границ требуется учесть граничные условия. Учет граничных условий. Граничные условия заданы в точках $x=0$ ($j=0$) и $x=l$ ($j=N$):
$y_0(t) = u_1(t)$ – задается значение решения на левом конце (дирихлеевое условие для смещения);
$y_{xx}(t,0) = u_2(t)$ – задается вторая производная (изгибающий момент) на левом конце;
$y_N(t) = u_3(t)$ – значение на правом конце;
$y_{xx}(t,l) = u_4(t)$ – вторая производная на правом конце.
В разностной схеме граничные условия первого типа ($y_0$ и $y_N$) непосредственно задаются известными значениями на каждом шаге по времени. Для учета условий на вторую производную вводим фиктивные узлы вне границ, значение в которых выбирается из условия $y_{xx}$:
Слева введем фиктивный узел $j=-1$ с $x_{-1}=-\Delta x$. Из условия $y_{xx}(t,0) = u_2(t)$ получаем соотношение:
𝑦
−
1
(
𝑡
)
−
2
 
𝑦
0
(
𝑡
)
+
𝑦
1
(
𝑡
)
Δ
𝑥
2
=
𝑢
2
(
𝑡
)
.
Δx 
2
 
y 
−1
​
 (t)−2y 
0
​
 (t)+y 
1
​
 (t)
​
 =u 
2
​
 (t).
Отсюда выражаем значение в фиктивном узле:
𝑦
−
1
(
𝑡
)
=
2
 
𝑦
0
(
𝑡
)
−
𝑦
1
(
𝑡
)
+
𝑢
2
(
𝑡
)
 
Δ
𝑥
2
.
y 
−1
​
 (t)=2y 
0
​
 (t)−y 
1
​
 (t)+u 
2
​
 (t)Δx 
2
 .
Аналогично справа ($j=N+1$ с $x_{N+1}=l+\Delta x$):
𝑦
𝑁
+
1
(
𝑡
)
−
2
 
𝑦
𝑁
(
𝑡
)
+
𝑦
𝑁
−
1
(
𝑡
)
Δ
𝑥
2
=
𝑢
4
(
𝑡
)
,
Δx 
2
 
y 
N+1
​
 (t)−2y 
N
​
 (t)+y 
N−1
​
 (t)
​
 =u 
4
​
 (t),
откуда
𝑦
𝑁
+
1
(
𝑡
)
=
2
 
𝑦
𝑁
(
𝑡
)
−
𝑦
𝑁
−
1
(
𝑡
)
+
𝑢
4
(
𝑡
)
 
Δ
𝑥
2
.
y 
N+1
​
 (t)=2y 
N
​
 (t)−y 
N−1
​
 (t)+u 
4
​
 (t)Δx 
2
 .
Используя эти фиктивные значения, можем аппроксимировать $y_{xxxx}$ в узлах, ближайших к краям ($j=1$ и $j=N-1$):
Для $j=1$ (ближайший к левому краю внутренний узел) используем точки $j=-1,0,1,2,3$:
𝑦
𝑥
𝑥
𝑥
𝑥
(
𝑡
,
𝑥
1
)
≈
𝑦
−
1
(
𝑡
)
−
4
 
𝑦
0
(
𝑡
)
+
6
 
𝑦
1
(
𝑡
)
−
4
 
𝑦
2
(
𝑡
)
+
𝑦
3
(
𝑡
)
Δ
𝑥
4
.
y 
xxxx
​
 (t,x 
1
​
 )≈ 
Δx 
4
 
y 
−1
​
 (t)−4y 
0
​
 (t)+6y 
1
​
 (t)−4y 
2
​
 (t)+y 
3
​
 (t)
​
 .
Подставляя $y_{-1}(t) = 2y_0 - y_1 + u_2,\Delta x^2$ и учитывая, что $y_0 = u_1(t)$, получим:
𝑦
𝑥
𝑥
𝑥
𝑥
(
𝑡
,
𝑥
1
)
≈
−
2
 
𝑦
0
(
𝑡
)
+
5
 
𝑦
1
(
𝑡
)
−
4
 
𝑦
2
(
𝑡
)
+
𝑦
3
(
𝑡
)
+
𝑢
2
(
𝑡
)
 
Δ
𝑥
2
Δ
𝑥
4
.
y 
xxxx
​
 (t,x 
1
​
 )≈ 
Δx 
4
 
−2y 
0
​
 (t)+5y 
1
​
 (t)−4y 
2
​
 (t)+y 
3
​
 (t)+u 
2
​
 (t)Δx 
2
 
​
 .
Аналогично для узла $j=N-1$:
𝑦
𝑥
𝑥
𝑥
𝑥
(
𝑡
,
𝑥
𝑁
−
1
)
≈
𝑦
𝑁
−
3
(
𝑡
)
−
4
 
𝑦
𝑁
−
2
(
𝑡
)
+
5
 
𝑦
𝑁
−
1
(
𝑡
)
−
2
 
𝑦
𝑁
(
𝑡
)
+
𝑢
4
(
𝑡
)
 
Δ
𝑥
2
Δ
𝑥
4
,
y 
xxxx
​
 (t,x 
N−1
​
 )≈ 
Δx 
4
 
y 
N−3
​
 (t)−4y 
N−2
​
 (t)+5y 
N−1
​
 (t)−2y 
N
​
 (t)+u 
4
​
 (t)Δx 
2
 
​
 ,
где учтено $y_{N+1}(t) = 2y_N - y_{N-1} + u_4,\Delta x^2$. Таким образом, разностная аппроксимация оператора $y_{xxxx}$ построена с учетом управляемых граничных условий.
Шаговый алгоритм по времени
Для интегрирования во времени используем двуслойную схему, аппроксимирующую вторую производную $y_{tt}$ центральными разностями второго порядка. Пусть шаг по времени равен $\Delta t$, число шагов $M = T/\Delta t$. Обозначим $y_j^n \approx y(t_n, x_j)$, где $t_n = n,\Delta t$. Тогда схема имеет вид:
𝑦
𝑗
 
𝑛
+
1
−
2
 
𝑦
𝑗
 
𝑛
+
𝑦
𝑗
 
𝑛
−
1
Δ
𝑡
2
+
(
𝑦
𝑥
𝑥
𝑥
𝑥
)
𝑗
 
𝑛
=
0
,
Δt 
2
 
y 
j
n+1
​
 −2y 
j
n
​
 +y 
j
n−1
​
 
​
 +(y 
xxxx
​
 ) 
j
n
​
 =0,
где $(y_{xxxx})j^{,n}$ – дискретный оператор из предыдущего раздела, вычисленный по значениям $y{i}^{,n}$ на временном слое $n$. Перепишем для явной формы получения $y^{n+1}$:
𝑦
𝑗
 
𝑛
+
1
=
2
 
𝑦
𝑗
 
𝑛
−
𝑦
𝑗
 
𝑛
−
1
−
Δ
𝑡
2
 
(
𝑦
𝑥
𝑥
𝑥
𝑥
)
𝑗
 
𝑛
,
𝑗
=
1
,
2
,
…
,
𝑁
−
1.
y 
j
n+1
​
 =2y 
j
n
​
 −y 
j
n−1
​
 −Δt 
2
 (y 
xxxx
​
 ) 
j
n
​
 ,j=1,2,…,N−1.
Здесь $j=1,\dots,N-1$ – внутренние узлы, для которых используется формула на основе соседних значений, включая фиктивные, как описано выше. Для граничных узлов $j=0$ и $j=N$ непосредственно задаются управления:
𝑦
0
𝑛
=
𝑢
1
(
𝑡
𝑛
)
,
𝑦
𝑁
𝑛
=
𝑢
3
(
𝑡
𝑛
)
для каждого 
𝑛
.
y 
0
n
​
 =u 
1
​
 (t 
n
​
 ),y 
N
n
​
 =u 
3
​
 (t 
n
​
 )для каждого n.
При вычислении $(y_{xxxx})_j^n$ на краевых внутренних узлах $j=1$ и $j=N-1$ используются текущие значения управлений $u_2(t_n), u_4(t_n)$ через фиктивные узлы (формулы приведены выше). Начальный шаг. На нулевом временном слое $n=0$ заданы $y_j^0 = 0$. Скорость $y_t(0,x)=0$ соответствует условию $y_j^{-1}=y_j^0$ (т.е. нулевому приращению за шаг до $t=0$). Это гарантирует, что первая итерация схемы не приведет к ``скачку'' решения. Таким образом, стартовые слои можно положить $y_j^{-1}=0$ и $y_j^0=0$ для всех $j$. Условие устойчивости. Полученная схема – явно-двухслойная (аналогична схеме для волнового уравнения, но с четвертым порядком по $x$). Она будет устойчивой при достаточно малом шаге $\Delta t$, удовлетворяющем условию Куранта. Оценим порядок ограничения: для наивысших гармоник ($\lambda \sim \frac{\pi}{\Delta x}$) фазовая скорость уравнения $y_{tt}+y_{xxxx}=0$ растет как $v_{\text{ph}} \sim \frac{1}{\Delta x}$ (поскольку для моды с длиной волны $\sim 2\Delta x$ частота $\omega \approx k^2$ высока). Это приводит к условию порядка $\Delta t \lesssim C,\Delta x^2$ (более жесткому, чем для классического волнового уравнения). На практике для обеспечения устойчивости явной схемы $\Delta t$ выбирают пропорциональным $\Delta x^2$ с достаточным запасом. При нарушении этого условия могут возникать неустойчивые высокочастотные колебания. Для борьбы с ними можно либо уменьшать шаг $\Delta t$, либо использовать неявные схемы (например, алгоритм Ньюмарка) – они позволяют брать больший шаг по времени за счет решения линейных систем на каждом шаге. В данной работе для простоты предполагается выбор $\Delta t$, удовлетворяющего условию устойчивости явной схемы.
Пошаговая корректировка управления
Поскольку конечная цель $y(T,x)=f(x)$ должна достигаться за счет граничного воздействия, подходящей стратегией является итерационный алгоритм управления, основанный на последовательном интегрировании уравнения вперед во времени и небольших коррекциях управлений. Этот подход реализует идею градиентного (спускового) методa по времени и соответствует методу сопряженного уравнения, но без явного формирования и инверсии глобальной матрицы. Основные шаги алгоритма за одну итерацию:
Прямой прогон (эволюция состояния). Задаются текущие предположения о функциях управления $u_1^n, u_2^n, u_3^n, u_4^n$ для $0 \le n \le M$ (например, нулевые функции на первой итерации). Затем, используя разностную схему, рассчитывается траектория $y_j^n$ при $n=0,\dots,M$ от $t=0$ до $t=T$. В конце этого шага получаем приближенное состояние в момент $T$: $y_j^M \approx y(T,x_j)$.
Вычисление отклонения от цели. Рассчитывается невязка (ошибка) на конечном состоянии:
𝑒
𝑗
=
𝑦
𝑗
𝑀
−
𝑓
(
𝑥
𝑗
)
,
e 
j
​
 =y 
j
M
​
 −f(x 
j
​
 ),
для всех узлов $j=0,\dots,N$. Если невязка малы (например, в норме $|e|$ ниже заданного порога), управление считается найденным. Иначе переходим к следующему шагу.
Обратный прогон (сопряженное уравнение). Решается сопряженная задача от $t=T$ к $t=0$ для определения градиента функционала качества по управлениям. Пусть функционал оценки достигаемой цели – например, квадрат нормы отклонения $\displaystyle J = \frac{1}{2}\sum_j (y_j^M - f(x_j))^2$. Тогда градиенты управления $g_{u_i}(t_n)$ можно получить через решение сопряженного уравнения:
𝜙
𝑡
𝑡
(
𝑡
,
𝑥
)
+
𝜙
𝑥
𝑥
𝑥
𝑥
(
𝑡
,
𝑥
)
=
0
,
𝜙
(
𝑇
,
𝑥
)
=
𝑦
(
𝑇
,
𝑥
)
−
𝑓
(
𝑥
)
,
𝜙
𝑡
(
𝑇
,
𝑥
)
=
0
,
ϕ 
tt
​
 (t,x)+ϕ 
xxxx
​
 (t,x)=0,ϕ(T,x)=y(T,x)−f(x),ϕ 
t
​
 (T,x)=0,
с соответствующими однородными граничными условиями, сопряженными к управляемым:
𝜙
𝑥
(
0
,
𝑡
)
=
0
,
𝜙
𝑥
𝑥
𝑥
(
0
,
𝑡
)
=
0
,
𝜙
𝑥
(
𝑙
,
𝑡
)
=
0
,
𝜙
𝑥
𝑥
𝑥
(
𝑙
,
𝑡
)
=
0
,
(
0
<
𝑡
<
𝑇
)
.
ϕ 
x
​
 (0,t)=0,ϕ 
xxx
​
 (0,t)=0,ϕ 
x
​
 (l,t)=0,ϕ 
xxx
​
 (l,t)=0,(0<t<T).
Эти условия получаются из условий стационарности граничных членов вариации функционала и соответствуют тому, что в оптимуме влияние вариаций $u_1, \dots, u_4$ отсутствует. На практике они применяются для вычисления $\phi$ при обратном интегрировании.
Примечание: $\phi(t,x)$ можно трактовать как решение того же уравнения колебаний балки, распространяющееся от конечного состояния ошибки назад во времени. Граничные условия $\phi_x=0, \phi_{xxx}=0$ означают, что на концах балка ``свободна'' для $\phi$ (отсутствуют изгибающий момент и поперечная сила) – это сопряженные граничные условия к управляемым смещению и моменту соответственно.
Численное решение этой задачи проводится аналогично прямому интегрированию, но во временном цикле от $n=M$ к $n=0$. Начальные (в терминологии обратного времени – конечные) условия $\phi_j^M = e_j$, $\phi_j^{M+1} = \phi_j^M$ (что эквивалентно $\phi_t(T)=0$) и граничные условия $\phi_x(0)=\phi_{xxx}(0)=0$, $\phi_x(l)=\phi_{xxx}(l)=0$ позволяют запустить обратный счет. Получаем в итоге историю поля $\phi_j^n$ на промежутке $0 \le n \le M$.
Вычисление градиентов управления. По найденному полю $\phi(t,x)$ определяем производные, входящие в условия сопряженности. В соответствии с интегральными соотношениями (получаемыми интегрированием по частям исходного уравнения с учетом граничных условий), вариация функционала по $u_i(t)$ выражается через решение $\phi(t,x)$ как:
𝛿
𝐽
𝛿
𝑢
1
(
𝑡
)
=
−
𝜙
𝑥
𝑥
𝑥
(
𝑡
,
0
)
,
𝛿
𝐽
𝛿
𝑢
2
(
𝑡
)
=
−
𝜙
𝑥
(
𝑡
,
0
)
,
δu 
1
​
 (t)
δJ
​
 =−ϕ 
xxx
​
 (t,0), 
δu 
2
​
 (t)
δJ
​
 =−ϕ 
x
​
 (t,0),
𝛿
𝐽
𝛿
𝑢
3
(
𝑡
)
=
−
𝜙
𝑥
𝑥
𝑥
(
𝑡
,
𝑙
)
,
𝛿
𝐽
𝛿
𝑢
4
(
𝑡
)
=
−
𝜙
𝑥
(
𝑡
,
𝑙
)
.
δu 
3
​
 (t)
δJ
​
 =−ϕ 
xxx
​
 (t,l), 
δu 
4
​
 (t)
δJ
​
 =−ϕ 
x
​
 (t,l).
Это – компоненты градиента антиповерхностного функционала. Знак ``минус'' появляется из условий стационарности, но его удобно учесть на этапе обновления, выбрав соответствующее направление шага. На практике вычисляются дискретные аналоги $\phi_x$ и $\phi_{xxx}$ в моменты времени $t_n$:
$\phi_x(0,t_n)$ приближенно через разность $\displaystyle \frac{\phi_1^n - \phi_{-1}^n}{2\Delta x}$ (с учетом $\phi_{-1}^n = \phi_1^n$, т.к. $\phi_x(0)=0$),
$\phi_{xxx}(0,t_n)$ – через однотороннюю разностную формулу четвертого порядка, например:
𝜙
𝑥
𝑥
𝑥
(
0
)
≈
−
5
𝜙
0
+
18
𝜙
1
−
24
𝜙
2
+
14
𝜙
3
−
3
𝜙
4
2
 
Δ
𝑥
3
,
ϕ 
xxx
​
 (0)≈ 
2Δx 
3
 
−5ϕ 
0
​
 +18ϕ 
1
​
 −24ϕ 
2
​
 +14ϕ 
3
​
 −3ϕ 
4
​
 
​
 ,
(полученную из разложения в ряд Тейлора). Аналогичная формула с противоположными знаками коэффициентов применяется для $\phi_{xxx}(l)$.
Коррекция управлений. Имея градиенты, корректируем управления на следующей итерации по методу наискорейшего спуска:
𝑢
1
𝑛
𝑒
𝑤
(
𝑡
𝑛
)
=
𝑢
1
𝑜
𝑙
𝑑
(
𝑡
𝑛
)
−
𝛼
 
𝜙
𝑥
𝑥
𝑥
(
𝑡
𝑛
,
0
)
,
u 
1
new
​
 (t 
n
​
 )=u 
1
old
​
 (t 
n
​
 )−αϕ 
xxx
​
 (t 
n
​
 ,0),
𝑢
2
𝑛
𝑒
𝑤
(
𝑡
𝑛
)
=
𝑢
2
𝑜
𝑙
𝑑
(
𝑡
𝑛
)
−
𝛼
 
𝜙
𝑥
(
𝑡
𝑛
,
0
)
,
u 
2
new
​
 (t 
n
​
 )=u 
2
old
​
 (t 
n
​
 )−αϕ 
x
​
 (t 
n
​
 ,0),
𝑢
3
𝑛
𝑒
𝑤
(
𝑡
𝑛
)
=
𝑢
3
𝑜
𝑙
𝑑
(
𝑡
𝑛
)
−
𝛼
 
𝜙
𝑥
𝑥
𝑥
(
𝑡
𝑛
,
𝑙
)
,
u 
3
new
​
 (t 
n
​
 )=u 
3
old
​
 (t 
n
​
 )−αϕ 
xxx
​
 (t 
n
​
 ,l),
𝑢
4
𝑛
𝑒
𝑤
(
𝑡
𝑛
)
=
𝑢
4
𝑜
𝑙
𝑑
(
𝑡
𝑛
)
−
𝛼
 
𝜙
𝑥
(
𝑡
𝑛
,
𝑙
)
,
u 
4
new
​
 (t 
n
​
 )=u 
4
old
​
 (t 
n
​
 )−αϕ 
x
​
 (t 
n
​
 ,l),
где $\alpha>0$ – малый коэффициент шага спуска, обеспечивающий монотонное уменьшение невязки.
Повтор итераций. С новыми управлениями повторяем прямой прогон, оцениваем новую невязку в конце и при необходимости продолжаем итерационный процесс до достижения приемлемой точности.
Таким образом, алгоритм последовательно уточняет граничное воздействие, стремясь погасить отклонение $y(T,x) - f(x)$. В каждый момент времени используется локальная информация о сопряженном решении $\phi(t)$, не требуя глобального решения системы уравнений для всех управлений сразу. Пример псевдокода итерационного алгоритма:
python
Копировать
Редактировать
# Псевдокод: управление колебаниями балки
initialize u1, u2, u3, u4 as zero arrays of length M+1
for iteration in range(max_iter):
    # 1. Прямой расчет состояния
    y = forward_simulation(u1, u2, u3, u4)   # массив y[j][n]
    # 2. Вычисление ошибки в конце
    error = [y[j][M] - f(x_j) for j in range(N+1)]
    cost = norm(error)
    if cost < tolerance:
        break  # цель достигнута
    # 3-4. Обратный расчет сопряженного состояния 
    phi = backward_simulation(error)  # массив phi[j][n]
    # 5. Обновление управлений по градиенту
    for n in range(M+1):
        grad_u1 = - third_derivative_xxx(phi_at_time_n_at_x0)
        grad_u2 = - first_derivative_x(phi_at_time_n_at_x0)
        grad_u3 = - third_derivative_xxx(phi_at_time_n_at_xL)
        grad_u4 = - first_derivative_x(phi_at_time_n_at_xL)
        u1[n] += alpha * grad_u1
        u2[n] += alpha * grad_u2
        u3[n] += alpha * grad_u3
        u4[n] += alpha * grad_u4
Здесь функции forward_simulation и backward_simulation реализуют разностную схему, описанную ранее, а вычисление производных first_derivative_x и third_derivative_xxx выполняется с помощью разностных формул на границе.
Иллюстрация работы алгоритма
Предположим, целевая форма $f(x)$ – гладкая функция, например выпуклый изгиб балки (для примера возьмем $f(x) = \sin(\pi x/l)$, что обнуляется на концах)

. В начальный момент $y(0,x)\equiv 0$ (оранжевая линия на рисунке), отклонение от цели совпадает с $f(x)$ (желтая кривая). Алгоритм управления должен возбудить колебания балки через концы так, чтобы к моменту $T$ балка остановилась в положении $f(x)$. Несколько первых итераций градиентного метода будут постепенно уменьшать невязку. Управления $u_1(t)$ и $u_3(t)$ отвечают за непосредственное задание смещения концов, а $u_2(t)$ и $u_4(t)$ – за изгибающий момент, влияющий на кривизну краев балки. На рисунке ниже показано качественное поведение решения при управлении:
На начальном этапе (итерация 0) при нулевых управлениях конечное отклонение равно $-f(x)$ (балка остается в покое, а цель не достигнута).
После нескольких итераций управление возбуждает колебания: к моменту $T$ профиль балки близко подходит к целевому $f(x)$, уменьшая ошибку.
(Диаграмма: эволюция формы балки во времени с управлением, схематично показывающая снижение ошибки к $T$.)
Обсуждение численных особенностей
Сходимость и точность. Разработанная конечно-разностная схема является второго порядка по шагу $\Delta x$ и $\Delta t$. При достаточно малых шагах она аппроксимирует исходную задачу управления. В отсутствие управления ($u_i(t)\equiv0$) она точно сохраняет тривиальное решение $y=0$. При наличии управления ошибок аппроксимации могут приводить к небольшим отклонениям, но при уменьшении $\Delta x, \Delta t$ решение сходится к точному (при условии, что задача управления корректно разрешима). Устойчивость. Явная схема предъявляет жесткие ограничения на $\Delta t$. При их выполнении решение устойчиво, и итерационный процесс корректно сходится к оптимальному управлению. Если $\Delta t$ слишком велик, численный шум (высокочастотные компоненты $\phi$) при обратном интегрировании может приводить к росту градиента и нарушению сходимости. В таких случаях уменьшают шаг $\Delta t$ или вводят регуляризацию градиентного шага (уменьшение $\alpha$, фильтрацию высокочастотных компонентов). Численная контролируемость. Линейное уравнение Эйлера–Бернулли на конечном отрезке при наличии управлений $u_1,\dots,u_4$ теоретически точно управляемо за конечное время $T$, достаточное для распространения влияния от границ по всей длине балки. Алгоритм градиентного спуска на практике находит одно из возможных управлений (обычно минимизирующее некоторый функционал, например, энергию управления). В процессе итераций наблюдается затухание невязки. Скорость сходимости может снижаться для очень высоких мод и больших $T$ из-за обусловленности задачи (оператор управления имеет экспоненциально малые сингулярные числа для высокочастотных компонент). Тем не менее, метод сопряженного уравнения успешно справляется с нахождением управлений, избегая прямого решения огромной системы уравнений. Пример реализации на Python. Ниже приведен упрощенный код, иллюстрирующий один шаг прямого интегрирования и расчет оператора $y_{xxxx}$ с граничными условиями:
python
Копировать
Редактировать
# Прямой шаг интегрирования для одного временного слоя (Python-подобный псевдокод)
for j in range(1, N):  # внутренние узлы
    if j == 1:
        # учесть левый край через ghost_left
        ghost_left = 2*y0[n] - y1[n] + u2[n]*(dx**2)
        y_xxxx = (ghost_left - 4*y0[n] + 6*y1[n] - 4*y2[n] + y3[n]) / dx**4
        y1[n+1] = 2*y1[n] - y1[n-1] - (dt**2)*y_xxxx
    elif j == N-1:
        ghost_right = 2*yN[n] - y_{N-1}[n] + u4[n]*(dx**2)
        y_xxxx = (y_{N-3}[n] - 4*y_{N-2}[n] + 6*y_{N-1}[n] - 4*yN[n] + ghost_right) / dx**4
        y_{N-1}[n+1] = 2*y_{N-1}[n] - y_{N-1}[n-1] - (dt**2)*y_xxxx
    else:
        # обычный внутренний узел
        y_xxxx = (y_{j-2}[n] - 4*y_{j-1}[n] + 6*y_j[n] - 4*y_{j+1}[n] + y_{j+2}[n]) / dx**4
        y_j[n+1] = 2*y_j[n] - y_j[n-1] - (dt**2)*y_xxxx

# Граничные узлы заданы управлением:
y0[n+1] = u1[n+1]
yN[n+1] = u3[n+1]
Аналогично (с учетом фиктивных узлов для $\phi_xx=0$ и $\phi_{xxx}=0$) реализуется интегрирование уравнения для $\phi$ назад во времени. В целом, описанный численный метод позволяет решать задачи граничного управления колебаниями балки, шаг за шагом подбирая управляющие воздействия. Его преимущество – отсутствие необходимости решать глобальную систему уравнений размерности $4M \times 4M$ (где $M = T/\Delta t$) для нахождения оптимального управления; вместо этого используется локальная информация (решения прямой и сопряженной задач), что облегчает реализацию для больших $M$. Однако метод может требовать большого числа итераций при высоких требованиях к точности, и чувствителен к численным погрешностям. Для улучшения сходимости иногда применяют более сложные стратегии: например, методы сопряженного градиента в функциональных пространствах, регуляризацию или обратное время с малым искусственным демпфированием для стабилизации высокочастотных мод. Тем не менее, даже базовый градиентный алгоритм, как описан выше, демонстрирует успешное управление балкой к требуемому состоянию, подтверждая теоретическую управляемость системы.
